# Europa_Scraping


## A propos du projet

Bienvenue dans le repository d√©di√© √† notre projet Science Po pour le semestre 2 de 2023. Ce repository est destin√© √† rassembler notre code et faciliter la collaboration entre nous.

Notre projet consiste √† effectuer du web scraping sur le site https://ec.europa.eu/clima/ets/welcome.do?languageCode=fr afin de collecter des donn√©es pr√©cises.

De notre cot√© le projet est fini, mais n'h√©sitez pas √† le copier ou √† vous en inspirer pour vos propres projets.


### language utilis√©

Python 3.10.5 - Projet Scrapy  
<br>


<!-- GETTING STARTED -->
## Pour commencer

### Pr√©-requis

Pour l'extraction de donn√©es
- Scrapy 2.7.1  
les autres librairies tel que **logging** et **datetime** devrait √™tre integr√© dans la biblioth√®que standart de votre version python  

Pour les dashboards
- numpy 1.24.1 pour manipuler les donn√©es
- pandas 1.5.3 pour manipuler les donn√©es
- plotly 5.13.1 pour cr√©er des graphiques
- dash 2.9.1 pour d√©velopper des applications web pour la visualisation des donn√©es
- geopy 2.3.0 to get latitude and longitude coordinates for addresses 
- folium 0.14.0 to create an interactive map centered on the mean Latitude and Longitude of the holding accounts

### Installation

1. Cloner le d√©p√¥t du projet : git clone https://github.com/MunznerLouis/Europa_Scraping

2. Naviguer dans le r√©pertoire du projet : cd votre-projet

3. Installer les d√©pendances : pip install -r requirements.txt  
<br>


<!-- USAGE EXAMPLES -->
## Utilisation
### Pour le Scraping
Pour lancer une Spider contenu dans le dossier 'spiders' du projet :    
  
1. Dans votre environnement ,lancez la commande suivante :  
scrapy runspdier [fichier spider qu'on veut lancer] exemple:  
-**scrapy runspider europa_spider.py**  
Cela aura pour effet de scraper le site, mais les donn√©es seront sauvegard√©es nulle part  
pour sauvegarder les donn√©es quelque part, suivre l'√©tape 2 : 

2. lancer la commande suivante :   
scrapy runspider [fichier de la classe spider] -O [nom de fichier avec son extension]  
le 'o' peut etre en majuscule si on veut Override le fichier du m√™me nom  
exemple :  
-**scrapy runspider europa_spider.py -O ../../data.csv**    
  
PS : l'√©tape 2 remplace l'√©tape 1 dans le cas ou on veut sauvegarder les donn√©es scrap√©es  

### Pour les dashboards
Dans votre environnement ,lancez la commande suivante :  
python nom_fichier.py  
<br>

## Resultats Scraping

les deux spiders se trouve √† cette endroit dans le projet  :
```\scrapy_scraper\scrapy_scraper\spiders\```  :

- europa_spider.py  (pour la partie des sites polluants)
- transaction_spider.py  (pour la partie transaction)

pour ce qui est de nos .csv il s'agit de :
- data_holding_account.csv  (13Mo)
    - 250 colonnes
    - nombre de lignes : 17 910
    - temps de scraping : ~13min (15requetes/s)
- data_transaction.csv  (200Mo)
    - 15 colonnes
    - nombre de lignes : 1 106 821
    - temps de scraping : ~13heure (18requetes/s)

## Resultats Dashboard

Avec les donn√©es collect√©s nous avons pu cr√©er une carte interactive pour permettre de visualiser des informations li√©es aux entreprises lorsqu'on passe la souris dessus. Nous avons aussi pu produire plusieurs graphiques permettant de mieux comprendre les donn√©es extraites lors du scraping.

<img src="dashboard/Plot_Screenshots/Holding_map.png" alt="Holding map" width="65%">
<img src="dashboard/Plot_Screenshots/mouse_Hover.png" alt="Mouse hover" width="45%">

Nous avons √©galement pu produire plusieurs graphs, mais dans l'optique de ne pas inonder le ReadMe nous ne les pr√©senterons pas tous : 
<img src="dashboard/Plot_Screenshots/top_10_Polluting_Countries.png" alt="Mouse hover" width="100%">

<!-- CONTRIBUTING -->

## Contribution

Nous sommes heureux de vous annoncer que notre projet Science Po pour le semestre 2 de 2023 est d√©sormais termin√©. (On a eu 18/20!ü•≥)

Nous souhaitons cependant vous informer que ce repository ne sera plus mis √† jour et n'acceptera donc plus de contributions. N√©anmoins, nous vous encourageons vivement √† vous inspirer de notre code ou √† le copier pour vos propres projets si cela peut vous √™tre utile.

<!-- CONTACT -->
## Contact

- M√ºnzner Louis - munzner.louis@gmail.com 

- Brise Quentin - brisequent@cy-tech.fr 

- Zeddam Hatem - zeddamhate@cy-tech.fr  

- Noyes Enzo - noyesenzo@cy-tech.fr   

Project Link: [https://github.com/MunznerLouis/Europa_Scraping](https://github.com/MunznerLouis/Europa_Scraping)


